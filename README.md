ğŸ“˜ Interpretable Credit Default Prediction using XGBoost & SHAP

This project builds a complete Credit Default Risk Prediction System using the UCI Credit Card Dataset, applying advanced preprocessing, XGBoost modeling, hyperparameter tuning, and SHAP explainability for global and local interpretation of model behavior.

The goal is not only to achieve strong predictive performance but also to provide transparent, interpretable insights that are valuable in real-world financial decision-making, such as loan approvals, risk scoring, and fairness evaluation.

ğŸ§  Project Highlights
âœ”ï¸ End-to-End ML Pipeline

Data loading

Preprocessing (missing values, encoding, scaling)

XGBoost classification

GridSearchCV tuning

Performance evaluation

âœ”ï¸ Explainable AI

Traditional feature importance (XGBoost gain)

SHAP global importance

SHAP local explanations (force & waterfall plots)

Interpretation of decisions for individual applicants

âœ”ï¸ Fully Reproducible

All outputs are automatically saved to /outputs/ so the analysis can be reproduced or audited easily.

âœ”ï¸ Ready for GitIngest

This repository follows the exact structure required for automated submission.

ğŸ“‚ Repository Structure
credit_shap_project/
â”‚
â”œâ”€â”€ README.md                     # Project documentation (this file)
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Clean ignore rules
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ credit_default_shap.ipynb # Full Colab notebook with complete pipeline
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ UCI_Credit_Card.csv       # Dataset (from Kaggle / UCI)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ model.joblib              # Saved XGBoost model
â”‚   â”œâ”€â”€ metrics.json              # Accuracy, F1, ROC-AUC, precision, recall
â”‚   â”œâ”€â”€ predictions.csv           # True vs predicted labels
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ shap_summary.png
â”‚   â”œâ”€â”€ shap_local_1.png
â”‚   â”œâ”€â”€ shap_local_2.png
â”‚   â”œâ”€â”€ shap_local_3.png
â”‚   â”œâ”€â”€ shap_force_1.html
â”‚   â”œâ”€â”€ shap_force_2.html
â”‚   â”œâ”€â”€ shap_force_3.html
â”‚   â”œâ”€â”€ technical_summary.txt
â”‚   â”œâ”€â”€ local_shap_interpretation.txt
â”‚   â””â”€â”€ final_business_analysis.txt
â”‚
â””â”€â”€ src/                          # optional scripts
    â”œâ”€â”€ train_model.py
    â”œâ”€â”€ preprocess.py
    â””â”€â”€ shap_analysis.py

ğŸ“Š Dataset Used

Dataset: UCI Credit Card Clients Dataset
Source: UCI Machine Learning Repository / Kaggle mirror
Task: Predict next-month default (binary classification)
Rows: 30,000
Features: Demographics, bill amounts, repayment history, credit limits, etc.

This dataset is ideal for:

Realistic credit risk modeling

XGBoost on mixed categorical + numerical data

SHAP-based explainability

Fairness and bias analysis

âš™ï¸ How to Run the Project (Google Colab)

Upload the repository or open the notebook:

notebook/credit_default_shap.ipynb


Mount Google Drive

Place dataset into:

/content/drive/MyDrive/credit_shap_project/data/


Run all cells in order

All outputsâ€”including SHAP plotsâ€”will be saved automatically to:

/outputs/

ğŸ“ˆ Model Performance Metrics (saved in metrics.json)

Includes:

Accuracy

F1 score

Precision & Recall

ROC-AUC

Confusion Matrix

These provide a complete evaluation of model predictive power.

ğŸ” Explainability Using SHAP

The project includes:

âœ” Global SHAP Summary Plot

Shows how features contribute to the overall model:

Top risk-inducing variables

Protective variables

Interaction behaviors

âœ” Local SHAP Plots for Individual Customers

Waterfall and Force plots for 3 cases:

True Positive

False Positive

False Negative
(or the closest available samples)

These help understand why the model decided someone might default.

ğŸ“ Included Reports

Inside /outputs/ you will find:

âœ” technical_summary.txt

Summarizes:

preprocessing

model tuning

evaluation

feature importance vs SHAP

âœ” local_shap_interpretation.txt

Explains 3 local SHAP plots:

Top contributing risk factors

Top mitigating factors

âœ” final_business_analysis.txt

â‰¤500-word high-level analysis covering:

Risk drivers

Fairness considerations

Business implications

Recommendations for lenders

ğŸš€ Technologies Used

Python 3

Pandas

NumPy

Scikit-learn

XGBoost

SHAP

Matplotlib & Seaborn

Google Colab

Joblib