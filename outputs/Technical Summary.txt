Technical Summary of Model Development, Tuning, and SHAP Interpretability

This project implements an end-to-end machine learning pipeline to predict next-month credit default using the UCI Credit Card Clients dataset. The workflow included data preprocessing, hyperparameter-tuned XGBoost modeling, model evaluation, and global/local interpretability analysis using SHAP.

The preprocessing pipeline was built using a ColumnTransformer with separate numeric and categorical branches. Missing values were imputed using median (numeric) and most frequent (categorical) strategies, and categorical features were one-hot encoded. This ensured full compatibility with XGBoost while preserving interpretability. The dataset was then split into training and testing sets using a stratified 80/20 split to maintain class balance.

Model training was performed using XGBoostClassifier, and hyperparameters were tuned using GridSearchCV across learning rate, max depth, and number of estimators. The best model achieved the following metrics on the test set: accuracy = 0.819, ROC-AUC = 0.779, precision = 0.668, recall = 0.360, and F1 = 0.468. While accuracy and precision were relatively strong, recall was lower, indicating the model is conservative in predicting default (reducing false positives but missing some true defaults). This is expected in financial risk modeling where precision is prioritized to avoid incorrectly flagging non-defaulting customers.

Model-based feature importance (gain) and SHAP global importance revealed strong consistency. The five most influential SHAP features were PAY_0, MARRIAGE, LIMIT_BAL, BILL_AMT5, and BILL_AMT1, aligning with known credit risk factors. PAY_0 (most recent payment status) was the most influential feature, confirming that recent delinquency strongly increases default risk. LIMIT_BAL and bill amounts (e.g., BILL_AMT5, BILL_AMT1) also contributed substantially, indicating the relationship between credit exposure, repayment behavior, and default likelihood. Interestingly, MARRIAGE appeared as an important feature, suggesting potential demographic patterns the model has learned, which raises fairness considerations.

Overall, the model successfully combines predictive performance with high interpretability. SHAP analysis provides transparent, individualized explanations, supporting regulatory requirements and enabling credit officers to understand model decisions at both population and applicant levels.