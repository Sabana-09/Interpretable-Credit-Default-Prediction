
Technical Summary of Model Development, Tuning, and SHAP Interpretability

Dataset & preprocessing:
- Dataset: UCI Credit Card Clients dataset (30k rows). Preprocessing used a ColumnTransformer:
  * Numeric: median imputation + StandardScaler
  * Categorical: most-frequent imputation + OneHotEncoder (handle_unknown='ignore')
- Train/test split: stratified 80/20 split.

Model & tuning:
- Model: XGBoost (XGBClassifier).
- GridSearchCV tuned: n_estimators ∈ {50,100}, max_depth ∈ {3,6}, learning_rate ∈ {0.1,0.01}.
- Best model: pipeline with the tuned XGBoost estimator.

Test performance (exact):
- Accuracy = 0.819
- F1 score = 0.4681684622918707
- Precision = 0.6685314685314685
- Recall = 0.3602110022607385
- ROC-AUC = 0.7796780588385458

Interpretability (model vs SHAP):
- Top 3 global features by SHAP importance:
  1. num__PAY_0 — most recent payment status
  2. num__MARRIAGE — demographic feature with strong influence
  3. num__LIMIT_BAL — total credit limit available
- Model-based feature importance (gain) was consistent with SHAP: recent repayment behavior (PAY_0) and credit exposure (LIMIT_BAL, BILL_AMT5, BILL_AMT1) rank among the top contributors.

Representative local SHAP numeric highlights:
- Case index 3560:
  * num__BILL_AMT5 = +0.3966
  * num__LIMIT_BAL = +0.2903
  * num__PAY_0      = +0.2901
  * num__MARRIAGE   = –0.3852
- Case index 17778:
  * num__PAY_0      = +1.21899
  * num__MARRIAGE   = –0.56125
  * num__LIMIT_BAL  = +0.23093
  * num__PAY_2 and PAY_6 ~ +0.24 each
- Case index 2156:
  * num__PAY_0      = –0.36474
  * num__LIMIT_BAL  = –0.32224
  * num__PAY_AMT1   = –0.29834

Overall, the model combines strong predictive performance with full interpretability through SHAP. The numeric SHAP values confirm repayment behavior is the most influential factor in default predictions.
