
1. Project Overview and Purpose

This technical summary documents the complete development process of a credit default prediction system built using the UCI Credit Card Default dataset, combined with XGBoost, GridSearchCV, and SHAP explainability. The purpose of the project is to demonstrate the ability to:

Build a full machine learning pipeline

Perform hyperparameter tuning

Evaluate predictive performance

Interpret the model using both global and local SHAP values

Understand model behavior and fairness risks

Communicate technical decisions in a transparent and business-friendly manner

The system aims to predict whether a credit card customer will default in the next month, a common real-world financial risk problem.

2. Dataset Description

The dataset contains 30,000 customer records with 23 features, including:

Demographic attributes

SEX

EDUCATION

MARRIAGE

AGE

Credit exposure attributes

LIMIT_BAL (credit limit)

BILL_AMT1â€“6

PAY_AMT1â€“6

Repayment behavior attributes

PAY_0 (last monthâ€™s payment status)

PAY_2â€“PAY_6 (previous repayment statuses)

Target variable

default.payment.next.month

The dataset has mild class imbalance:

22â€“23% defaults

77â€“78% non-defaults

This imbalance influences the modelâ€™s precision/recall characteristics.

3. Preprocessing Strategy

A scikit-learn ColumnTransformer pipeline was used to systematically preprocess features.

3.1 Numeric Features

The following numeric columns were imputed using median imputation and scaled:

LIMIT_BAL

AGE

BILL_AMT1â€“6

PAY_AMT1â€“6

PAY_0â€“PAY_6 (treated as numeric because they are ordinal)

Why median?
Because BILL_AMT and PAY_AMT variables have skewed distributions.

Why scaling?
XGBoost does not require scaling, but scaling improves numerical stability and consistency.

3.2 Categorical Features

Categorical variables:

SEX

EDUCATION

MARRIAGE

These were preprocessed using:

Most frequent imputation

OneHotEncoding (handle_unknown='ignore')

This ensures the model remains robust even when unseen categories appear.

4. Machine Learning Pipeline

A complete end-to-end pipeline was built using:

Pipeline([
    ("preprocessor", ColumnTransformer(...)),
    ("model", XGBClassifier(...))
])


This ensures:

No data leakage

Consistent transformations across training and inference

SHAP values reflect the correctly preprocessed feature space

The pipeline was tuned using GridSearchCV with stratified 80/20 train-test split.

5. Hyperparameter Tuning

GridSearch parameters:

n_estimators: [50, 100]

max_depth: [3, 6]

learning_rate: [0.1, 0.01]

Total combinations: 8 models

Cross-validation (cv=3) was used to select the best estimator.

The best hyperparameters selected were:

n_estimators = 100

max_depth = 6

learning_rate = 0.1

This configuration balances model complexity and generalization.

ðŸš€ TECHNICAL SUMMARY (PART 2/3)

(Model Performance, SHAP Global, Feature Importance, Index Mapping)

6. Model Performance

Using the test set (6000 samples), the best model achieved:

Accuracy: 0.819

Precision: 0.6685

Recall: 0.3602

F1-score: 0.4682

ROCâ€“AUC: 0.7797

Interpretation:

The model is good at identifying true non-defaulters (precision is high).

The model misses some defaulters (recall is lower).

Threshold tuning can increase recall at the cost of precision.

These values match the saved metrics.json.

7. Global Model Explainability

Two perspectives were analyzed:

7.1 XGBoost Traditional Feature Importance (Gain)

The following are the gain contributions extracted from the booster:

{'f0': 6.89,
 'f1': 21.43,
 'f2': 7.55,
 'f3': 10.00,
 'f4': 6.45,
 'f5': 7.05,
 'f6': 339.11,
 'f7': 94.53,
 'f8': 44.56,
 'f9': 39.62,
 'f10': 38.02,
 'f11': 34.26,
 'f12': 15.12,
 'f13': 8.77,
 'f14': 8.52,
 'f15': 8.15,
 'f16': 6.32,
 'f17': 8.42,
 'f18': 12.91,
 'f19': 25.78,
 'f20': 21.16,
 'f21': 11.78,
 'f22': 10.08,
 'f23': 11.89}


Mapping them to actual feature names (using OHE positions), the modelâ€™s strongest features are:

Top XGBoost Features

PAY_0 (f6 â€“ extremely dominant)

PAY_2

PAY_3

PAY_4

PAY_5 / BILL_AMT5-related encodings

These represent recent repayment behavior, matching domain expectations.

7.2 SHAP Global Summary (shap_summary.png)

The SHAP plot indicates:

Top SHAP Features

num__PAY_0

num__MARRIAGE

num__LIMIT_BAL

num__BILL_AMT5

num__PAY_AMT1

Interpretation:

SHAP shows both repayment behavior and demographic/capacity features as important.

SHAP captures non-linear interactions better than XGBoost gain alone.

7.3 Comparative Insights
Aspect	XGBoost Gain	SHAP
Dominant Feature	PAY_0	PAY_0
Next Strongest	PAY_2â€“PAY_6	MARRIAGE, LIMIT_BAL
Captures Demographics	Weak	Strong
Measures Non-Linearity	No	Yes
Measures Direction	No	Yes

SHAP gives a more interpretable and human-understandable representation of risk factors.

ðŸš€ TECHNICAL SUMMARY (PART 3/3)

(Local SHAP Cases Summary, Limitations, Conclusion)

8. Local SHAP Explanation Summary (Full details in local_shap_interpretation.txt)

We analyzed three customers using SHAP force plots and waterfall charts.

Case 3560 â€” True Positive (1 â†’ 1)

High PAY_0 and BILL_AMT values increased predicted risk.

SHAP shows contributions like:

BILL_AMT5 = +0.3966

LIMIT_BAL = +0.2903

Case 2156 â€” True Negative (0 â†’ 0)

High LIMIT_BAL and strong repayment amounts pushed the risk downward.

Contributions included:

PAY_0 = â€“0.3647

LIMIT_BAL = â€“0.3222

Case 17778 â€” False Positive (0 â†’ 1, prob = 0.5896)

Model incorrectly predicted default because:

PAY_0 = 4

PAY_2 = 4

PAY_3 = 4

Large delinquency pattern overshadowed protective features.

Important fairness case because customer did not default.

9. Limitations Observed

Class imbalance impacts recall.

Over-reliance on PAY_X variables may introduce bias toward customers with sudden past-due statuses.

MARRIAGE appears as a top global SHAP feature â†’ requires fairness monitoring.

High-cardinality encodings can dilute model interpretability.

10. Conclusion

This project successfully demonstrates:

Building a full ML pipeline with preprocessing, modeling, cross-validation, and evaluation

Training an XGBoost classifier that achieves ~82% accuracy

Using SHAP to provide global and local interpretability

Identifying errors (False Positive for case #17778)

Understanding model behavior and fairness risks

Creating deliverables suitable for technical, business, and ethical evaluation

This technical summary consolidates the full workflow and prepares the foundation for deeper narrative explanations in the local_shap_interpretation.txt and final_business_analysis.txt reports.